{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, preprocessing, grid_search\n",
    "from sklearn.preprocessing import Imputer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, accuracy_score, \\\n",
    "mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials \n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "import category_encoders as ce\n",
    "from functools import partial\n",
    "np.random.seed(1338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metric_set(metric):\n",
    "    \n",
    "    global metric_score\n",
    "    global metric_grid_search\n",
    "    metric_functions = {'roc_auc_score' : [roc_auc_score, 'roc_auc'], 'average_precision_score' : \n",
    "                        [average_precision_score, 'average_precision'], 'f1_score' : [f1_score, 'f1'],\n",
    "                        'log_loss' : [log_loss, 'log_loss'], 'accuracy_score' : [accuracy_score, 'accuracy'],\n",
    "                        'mean_absolute_error' : [mean_absolute_error,'mean_absolute_error'],\n",
    "                        'mean_squared_error':[mean_squared_error, 'mean_squared_error'],\n",
    "                        'r2_score' : [r2_score, 'r2']\n",
    "                        }\n",
    "    \n",
    "    metric_score = metric_functions[metric][0]\n",
    "    metric_grid_search = metric_functions[metric][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_import(data, label_output, encode = None, split = True, stratify = True, split_size = 0.3):\n",
    "    \n",
    "    global Data\n",
    "    Data = data\n",
    "    #Reading the data, into a Data Frame.\n",
    "    global target_label\n",
    "    target_label = label_output\n",
    "\n",
    "    #Selcting the columns of string data type\n",
    "    names = data.select_dtypes(include = ['object'])\n",
    "    \n",
    "    #Converting string categorical variables to integer categorical variables.\n",
    "    label_encode(names.columns.tolist())\n",
    "    \n",
    "    if(target_label in names):\n",
    "        \n",
    "        columns = names.drop([target_label],axis=1).columns.tolist()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        columns = names\n",
    "        \n",
    "    #Data will be encoded to the form that the user enters\n",
    "    encoding = {'binary':binary_encode,'hashing':hashing_encode,'backward_difference'\n",
    "               :backward_difference_encode,'helmert':helmert_encode,'polynomial':\n",
    "               polynomial_encode,'sum':sum_encode,'label':label_encode}\n",
    "    \n",
    "    if(encode != None):\n",
    "        \n",
    "        #Once the above encoding techniques has been selected by the user, the appropriate encoding function is called\n",
    "        encoding[encode](columns)\n",
    "        \n",
    "    #This function intializes the dataframes that will be used later in the program\n",
    "    #data_initialize()\n",
    "    \n",
    "    #Splitting the data into to train and test sets, according to user preference\n",
    "    if(split == True):\n",
    "        \n",
    "        test_data = data_split(stratify,split_size)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for ensembling (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The dataframes will be used in the training phase of the ensemble models\n",
    "def second_level_train_data(predict_list, cross_val_X, cross_val_Y):\n",
    "    \n",
    "    #Converting the list of predictions into a dataframe, which will be used to train the stacking model.\n",
    "    global stack_X\n",
    "    stack_X = pd.DataFrame()\n",
    "    stack_X = stack_X.append(build_data_frame(predict_list))\n",
    "    \n",
    "    #Building a list that contains all the raw features, used as cross validation data for the base models.\n",
    "    global raw_features_X\n",
    "    raw_features_X = pd.DataFrame()\n",
    "    raw_features_X = raw_features_X.append(cross_val_X,ignore_index=True)\n",
    "    \n",
    "    #The data frame will contain the predictions and raw features  of the base models, for training the blending\n",
    "    #model\n",
    "    global blend_X\n",
    "    blend_X = pd.DataFrame()\n",
    "    blend_X = pd.concat([raw_features_X, stack_X], axis = 1, ignore_index = True)\n",
    "    \n",
    "    #Storing the cross validation dataset labels in the variable stack_Y, \n",
    "    #which will be used later to train the stacking and blending models.\n",
    "    global stack_Y\n",
    "    stack_Y = cross_val_Y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for ensembling (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The dataframes will be used in the testing phase of the ensemble models\n",
    "def second_level_test_data(predict_list, test_X, test_Y):\n",
    "    \n",
    "    #Converting the list of predictions into a dataframe, which will be used to test the stacking model.\n",
    "    global test_stack_X\n",
    "    test_stack_X = pd.DataFrame()\n",
    "    test_stack_X = test_stack_X.append(build_data_frame(predict_list))\n",
    "    \n",
    "    #Building a list that contains all the raw features, used as test data for the base models.\n",
    "    global test_raw_features_X\n",
    "    test_raw_features_X = pd.DataFrame()\n",
    "    test_raw_features_X = test_raw_features_X.append(test_X,ignore_index=True)\n",
    "    \n",
    "    #The data frame will contain the predictions and raw features of the base models, for testing the blending\n",
    "    #model\n",
    "    global test_blend_X\n",
    "    test_blend_X = pd.DataFrame()\n",
    "    test_blend_X = pd.concat([test_raw_features_X, test_stack_X], axis = 1, ignore_index = True)\n",
    "    \n",
    "    #Storing the cross validation dataset labels in the variable stack_Y, \n",
    "    #which will be used later to test the stacking and blending models.\n",
    "    global test_stack_Y\n",
    "    test_stack_Y = test_Y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that encodes the string values to numerical values.\n",
    "def label_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values.\n",
    "    encoder = ce.OrdinalEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using binary method.\n",
    "    encoder = ce.BinaryEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hashing_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using hashing method.\n",
    "    encoder = ce.HashingEncoder(cols = column_names, verbose = 1, n_components = 128)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Difference Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_difference_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using backward difference method.\n",
    "    encoder = ce.BackwardDifferenceEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helmert Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def helmert_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using helmert method.\n",
    "    encoder = ce.HelmertEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using sum method.\n",
    "    encoder = ce.SumEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values, using polynomial method.\n",
    "    encoder = ce.PolynomialEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing datasets\n",
    "def data_split(stratify, split_size):\n",
    "    \n",
    "    global Data\n",
    "    \n",
    "    #Stratified Split\n",
    "    if(stratify == True):\n",
    "        Data, test = train_test_split(Data, test_size = split_size, stratify = Data[target_label],random_state = 0)\n",
    "        \n",
    "    #Random Split\n",
    "    else:\n",
    "        Data, test = train_test_split(Data, test_size = split_size,random_state = 0) \n",
    "        \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is used to convert the predictions of the base models (numpy array) into a DataFrame.\n",
    "def build_data_frame(data):\n",
    "    \n",
    "    data_frame = pd.DataFrame(data).T\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trains the Gradient Boosting model.\n",
    "def train_gradient_boosting(train_X, train_Y, parameter_gradient_boosting):\n",
    "\n",
    "    #Hyperopt procedure, train the model with optimal paramter values\n",
    "    if(parameter_gradient_boosting['hyper_parameter_optimisation'] == True):\n",
    "        \n",
    "        model = gradient_boosting_parameter_optimisation(train_X, train_Y, parameter_gradient_boosting, \\\n",
    "                                             objective_gradient_boosting)\n",
    "        return model\n",
    "    \n",
    "    #Train the model with the parameter values entered by the user, no need to find otimal values\n",
    "    else:\n",
    "        \n",
    "        dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "        del parameter_gradient_boosting['hyper_parameter_optimisation']\n",
    "        model = xgb.train(parameter_gradient_boosting, dtrain)\n",
    "        return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining the parameters for the XGBoost (Gradient Boosting) Algorithm.\n",
    "def parameter_set_gradient_boosting(hyper_parameter_optimisation = False, eval_metric = None, booster = ['gbtree'],\\\n",
    "                                    silent = [0], eta = [0.3], gamma = [0], max_depth = [6],\\\n",
    "                                    min_child_weight = [1], max_delta_step = [0], subsample = [1],\\\n",
    "                                    colsample_bytree = [1], colsample_bylevel = [1], lambda_xgb = [1], alpha = [0],\\\n",
    "                                    tree_method = ['auto'], sketch_eps = [0.03], scale_pos_weight = [0],\\\n",
    "                                    lambda_bias = [0], objective = ['reg:linear'], base_score = [0.5],\\\n",
    "                                    num_class = None):\n",
    "\n",
    "    parameter_gradient_boosting = {}\n",
    "    #This variable will be used to check if the user wants to perform hyper parameter optimisation.\n",
    "    parameter_gradient_boosting['hyper_parameter_optimisation'] = hyper_parameter_optimisation\n",
    "    \n",
    "    #Setting objective and seed\n",
    "    parameter_gradient_boosting['objective'] = objective[0]\n",
    "    parameter_gradient_boosting['seed'] = 0\n",
    "    \n",
    "    if(num_class != None):\n",
    "        \n",
    "        parameter_gradient_boosting['num_class'] = num_class\n",
    "    \n",
    "    #If hyper parameter optimisation is false, we unlist the default values and/or the values that the user enters \n",
    "    #in the form of a list. Values have to be entered by the user in the form of a list, for hyper parameter \n",
    "    #optimisation = False, these values will be unlisted below\n",
    "    #Ex : booster = ['gbtree'](default value) becomes booster = 'gbtree'\n",
    "    #This is done beacuse for training the model, the model does not accept list type values\n",
    "    if(parameter_gradient_boosting['hyper_parameter_optimisation'] == False):\n",
    "        \n",
    "        #Setting the parameters for the Booster, list values are unlisted (E.x - booster[0])\n",
    "        parameter_gradient_boosting['booster'] = booster[0]\n",
    "        parameter_gradient_boosting['eval_metric'] = eval_metric[0]\n",
    "        parameter_gradient_boosting['eta'] = eta[0]\n",
    "        parameter_gradient_boosting['gamma'] = gamma[0]\n",
    "        parameter_gradient_boosting['max_depth'] = max_depth[0]\n",
    "        parameter_gradient_boosting['min_child_weight'] = min_child_weight[0]\n",
    "        parameter_gradient_boosting['max_delta_step'] = max_delta_step[0]\n",
    "        parameter_gradient_boosting['subsample'] = subsample[0]\n",
    "        parameter_gradient_boosting['colsample_bytree'] = colsample_bytree[0]\n",
    "        parameter_gradient_boosting['colsample_bylevel'] = colsample_bylevel[0]\n",
    "        parameter_gradient_boosting['base_score'] = base_score[0]\n",
    "        parameter_gradient_boosting['lambda_bias'] = lambda_bias[0]\n",
    "        parameter_gradient_boosting['alpha'] = alpha[0]\n",
    "        parameter_gradient_boosting['tree_method'] = tree_method[0]\n",
    "        parameter_gradient_boosting['sketch_eps'] = sketch_eps[0]\n",
    "        parameter_gradient_boosting['scale_pos_weigth'] = scale_pos_weight[0]\n",
    "        parameter_gradient_boosting['lambda'] = lambda_xgb[0]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #Setting parameters for the Booster which will be optimized later using hyperopt.\n",
    "        #The user can enter a list of values that he wants to optimize\n",
    "        parameter_gradient_boosting['booster'] = booster\n",
    "        parameter_gradient_boosting['eval_metric'] = eval_metric\n",
    "        parameter_gradient_boosting['eta'] = eta\n",
    "        parameter_gradient_boosting['gamma'] = gamma\n",
    "        parameter_gradient_boosting['max_depth'] = max_depth\n",
    "        parameter_gradient_boosting['min_child_weight'] = min_child_weight\n",
    "        parameter_gradient_boosting['max_delta_step'] = max_delta_step\n",
    "        parameter_gradient_boosting['subsample'] = subsample\n",
    "        parameter_gradient_boosting['colsample_bytree'] = colsample_bytree\n",
    "        parameter_gradient_boosting['colsample_bylevel'] = colsample_bylevel\n",
    "        parameter_gradient_boosting['base_score'] = base_score\n",
    "        parameter_gradient_boosting['lambda_bias'] = lambda_bias\n",
    "        parameter_gradient_boosting['alpha'] = alpha\n",
    "        parameter_gradient_boosting['tree_method'] = tree_method\n",
    "        parameter_gradient_boosting['sketch_eps'] = sketch_eps\n",
    "        parameter_gradient_boosting['scale_pos_weigth'] = scale_pos_weight\n",
    "        parameter_gradient_boosting['lambda'] = lambda_xgb\n",
    "        \n",
    "    return parameter_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using the loss values, this function picks the optimum parameter values. These values will be used \n",
    "#for training the model\n",
    "def gradient_boosting_parameter_optimisation(train_X, train_Y, parameter_gradient_boosting,obj):\n",
    "    \n",
    "    space_gradient_boosting = assign_space_gradient_boosting(parameter_gradient_boosting)\n",
    "    trials = Trials()\n",
    "    \n",
    "    #Best is used to otmize the objective function\n",
    "    best = fmin(fn = partial(obj, data_X = train_X, data_Y = train_Y\\\n",
    "                             , parameter_gradient_boosting = parameter_gradient_boosting),\n",
    "    space = space_gradient_boosting,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 100,\n",
    "    trials = trials)\n",
    "    \n",
    "    optimal_param={}\n",
    "    #Best is a dictionary that contains the indices of the optimal parameter values.\n",
    "    #The following for loop uses these indices to obtain the parameter values, these values are stored in a\n",
    "    #dictionary - optimal_param\n",
    "    for key in best:\n",
    "        optimal_param[key] = parameter_gradient_boosting[key][best[key]]\n",
    "        \n",
    "    optimal_param['objective'] = parameter_gradient_boosting['objective']\n",
    "    optimal_param['eval_metric'] = parameter_gradient_boosting['eval_metric']\n",
    "    optimal_param['seed'] = parameter_gradient_boosting['seed']\n",
    "    \n",
    "    #Training the model with the optimal parameter values\n",
    "    dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "    model = xgb.train(optimal_param, dtrain)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function calculates the loss for different parameter values and is used to determine the most optimum \n",
    "#parameter values\n",
    "def objective_gradient_boosting(space_gradient_boosting, data_X, data_Y, parameter_gradient_boosting):\n",
    "    \n",
    "    #Gradient Boosting (XGBoost)\n",
    "    param = {}\n",
    "    #Setting Parameters for the Booster\n",
    "    param['booster'] = space_gradient_boosting['booster']\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eval_metric'] = parameter_gradient_boosting['eval_metric']\n",
    "    param['eta'] = space_gradient_boosting['eta']\n",
    "    param['gamma'] = space_gradient_boosting['gamma']\n",
    "    param['max_depth'] = space_gradient_boosting['max_depth']\n",
    "    param['min_child_weight'] = space_gradient_boosting['min_child_weight']\n",
    "    param['max_delta_step'] = space_gradient_boosting['max_delta_step']\n",
    "    param['subsample'] = space_gradient_boosting['subsample']\n",
    "    param['colsample_bytree'] = space_gradient_boosting['colsample_bytree']\n",
    "    param['colsample_bylevel'] = space_gradient_boosting['colsample_bylevel']\n",
    "    param['alpha'] = space_gradient_boosting['alpha']\n",
    "    param['scale_pos_weigth'] = space_gradient_boosting['scale_pos_weigth']\n",
    "    param['base_score'] = space_gradient_boosting['base_score']\n",
    "    param['lambda_bias'] = space_gradient_boosting['lambda_bias']\n",
    "    param['lambda'] = space_gradient_boosting['lambda']\n",
    "    param['tree_method'] = space_gradient_boosting['tree_method']\n",
    "    \n",
    "    model = xgb.Booster()\n",
    "    metric_list = list()\n",
    "\n",
    "    #Performing cross validation.\n",
    "    skf=StratifiedKFold(data_Y, n_folds=3,random_state=0)\n",
    "    for train_index, cross_val_index in skf:\n",
    "        \n",
    "        xgb_train_X, xgb_cross_val_X = data_X.iloc[train_index],data_X.iloc[cross_val_index]\n",
    "        \n",
    "        xgb_train_Y, xgb_cross_val_Y = data_Y.iloc[train_index],data_Y.iloc[cross_val_index]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(xgb_train_X, label = xgb_train_Y)\n",
    "        model = xgb.train(param, dtrain)\n",
    "        \n",
    "        predicted_values = model.predict(xgb.DMatrix(xgb_cross_val_X, label = xgb_cross_val_Y))\n",
    "        \n",
    "        if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "            \n",
    "            predictions = predicted_values >= 0.5\n",
    "            predictions.astype(int)\n",
    "            metric_list.append(metric_score(xgb_cross_val_Y,predictions))\n",
    "            \n",
    "        else :\n",
    "            \n",
    "            metric_list.append(metric_score(xgb_cross_val_Y,predicted_values))\n",
    "            \n",
    "        \n",
    "    \n",
    "    #Calculating the AUC and returning the loss, which will be minimised by selecting the optimum parameters.\n",
    "    metric = np.mean(metric_list)\n",
    "    return{'loss':1-metric, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning the values of the XGBoost parameters that need to be checked, for minimizing the objective (loss).\n",
    "#The values that give the most optimum results will be picked to train the model.\n",
    "def assign_space_gradient_boosting(parameter_gradient_boosting):\n",
    "    \n",
    "\n",
    "    space_gradient_boosting ={\n",
    "        \n",
    "        'booster': hp.choice('booster', parameter_gradient_boosting['booster']),\n",
    "        \n",
    "        'eta': hp.choice('eta', parameter_gradient_boosting['eta']),\n",
    "        \n",
    "        'gamma': hp.choice('gamma', parameter_gradient_boosting['gamma']),\n",
    "        \n",
    "        'max_depth': hp.choice('max_depth', parameter_gradient_boosting['max_depth']),\n",
    "        \n",
    "        'min_child_weight': hp.choice('min_child_weight', parameter_gradient_boosting['min_child_weight']),\n",
    "        \n",
    "        'max_delta_step': hp.choice('max_delta_step', parameter_gradient_boosting['max_delta_step']),\n",
    "        \n",
    "        'subsample': hp.choice('subsample', parameter_gradient_boosting['subsample']),\n",
    "        \n",
    "        'colsample_bytree': hp.choice('colsample_bytree', parameter_gradient_boosting['colsample_bytree']),\n",
    "        \n",
    "        'colsample_bylevel': hp.choice('colsample_bylevel', parameter_gradient_boosting['colsample_bylevel']),\n",
    "        \n",
    "        'alpha': hp.choice('alpha', parameter_gradient_boosting['alpha']),\n",
    "        \n",
    "        'scale_pos_weigth': hp.choice('scale_pos_weigth', parameter_gradient_boosting['scale_pos_weigth']),\n",
    "        \n",
    "        'base_score': hp.choice('base_score', parameter_gradient_boosting['base_score']),\n",
    "        \n",
    "        'lambda_bias': hp.choice('lambda_bias', parameter_gradient_boosting['lambda_bias']),\n",
    "        \n",
    "        'lambda': hp.choice('lambda', parameter_gradient_boosting['lambda']),\n",
    "        \n",
    "        'tree_method': hp.choice('tree_method', parameter_gradient_boosting['tree_method'])\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return space_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_gradient_boosting(data_X, data_Y, gradient_boosting):\n",
    "    \n",
    "    predicted_values = gradient_boosting.predict(xgb.DMatrix(data_X, label = data_Y))\n",
    "            \n",
    "    metric = metric_score(data_Y,predicted_values)\n",
    "\n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trains the Decision Tree model. Performing a grid search to select the optimal parameter values\n",
    "def train_decision_tree(train_X, train_Y, parameters_decision_tree):\n",
    "    \n",
    "    decision_tree_model = DecisionTreeClassifier()      \n",
    "    model_gs = grid_search.GridSearchCV(decision_tree_model, parameters_decision_tree, scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_decision_tree(data_X, data_Y, decision_tree):\n",
    "    \n",
    "    predicted_values = decision_tree.predict_proba(data_X)[:, 1]\n",
    "    \n",
    "    if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "        \n",
    "        predictions = decision_tree.predict(data_X)\n",
    "        metric = metric_score(data_Y, predictions)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_set_decision_tree(criterion = ['gini'], splitter = ['best'], max_depth = [None],\\\n",
    "                                min_samples_split = [2], min_samples_leaf = [1], min_weight_fraction_leaf = [0.0],\\\n",
    "                                max_features = [None], random_state = [None], max_leaf_nodes = [None],\\\n",
    "                                class_weight = [None], presort = [False]):\n",
    "    \n",
    "    parameters_decision_tree = {}\n",
    "    parameters_decision_tree['criterion'] = criterion\n",
    "    parameters_decision_tree['splitter'] = splitter\n",
    "    parameters_decision_tree['max_depth'] = max_depth\n",
    "    parameters_decision_tree['min_samples_split'] = min_samples_split\n",
    "    parameters_decision_tree['min_samples_leaf'] = min_samples_leaf\n",
    "    parameters_decision_tree['min_weight_fraction_leaf'] = min_weight_fraction_leaf\n",
    "    parameters_decision_tree['max_features'] = max_features\n",
    "    parameters_decision_tree['random_state'] = random_state\n",
    "    parameters_decision_tree['max_leaf_nodes'] = max_leaf_nodes\n",
    "    parameters_decision_tree['class_weight'] = class_weight\n",
    "    parameters_decision_tree['presort'] = presort\n",
    "    \n",
    "    return parameters_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trains the Random Forest model. Performing a grid search to select the optimal parameter values\n",
    "def train_random_forest(train_X, train_Y, parameters_random_forest):\n",
    "    \n",
    "    random_forest_model = RandomForestClassifier()\n",
    "    model_gs = grid_search.GridSearchCV(random_forest_model, parameters_random_forest, scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_random_forest(data_X, data_Y, random_forest):\n",
    "    \n",
    "    predicted_values = random_forest.predict_proba(data_X)[:, 1]\n",
    "    \n",
    "    if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "        \n",
    "        predictions = random_forest.predict(data_X)\n",
    "        metric = metric_score(data_Y, predictions)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for random forest. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#and the optimal value in that list will be picked using grid search\n",
    "def parameter_set_random_forest(n_estimators = [10], criterion = ['gini'], max_depth = [None],\\\n",
    "                                min_samples_split = [2], min_samples_leaf = [1], min_weight_fraction_leaf = [0.0],\\\n",
    "                                max_features = ['auto'], max_leaf_nodes = [None], bootstrap = [True],\\\n",
    "                                oob_score = [False], random_state = [None], verbose = [0],warm_start = [False],\\\n",
    "                                class_weight = [None]):\n",
    "    \n",
    "    parameters_random_forest = {}\n",
    "    parameters_random_forest['criterion'] = criterion\n",
    "    parameters_random_forest['n_estimators'] = n_estimators\n",
    "    parameters_random_forest['max_depth'] = max_depth\n",
    "    parameters_random_forest['min_samples_split'] = min_samples_split\n",
    "    parameters_random_forest['min_samples_leaf'] = min_samples_leaf\n",
    "    parameters_random_forest['min_weight_fraction_leaf'] = min_weight_fraction_leaf\n",
    "    parameters_random_forest['max_features'] = max_features\n",
    "    parameters_random_forest['random_state'] = random_state\n",
    "    parameters_random_forest['max_leaf_nodes'] = max_leaf_nodes\n",
    "    parameters_random_forest['class_weight'] = class_weight\n",
    "    parameters_random_forest['bootstrap'] = bootstrap\n",
    "    parameters_random_forest['oob_score'] = oob_score\n",
    "    parameters_random_forest['warm_start'] = warm_start\n",
    "    \n",
    "    return parameters_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trains the Linear Regression model. Performing a grid search to select the optimal parameter values\n",
    "def train_linear_regression(train_X, train_Y, parameters_linear_regression):\n",
    "    \n",
    "    linear_regression_model = linear_model.LinearRegression()\n",
    "    train_X=StandardScaler().fit_transform(train_X)\n",
    "    model_gs = grid_search.GridSearchCV(linear_regression_model, parameters_linear_regression,\\\n",
    "                                        scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_linear_regression(data_X, data_Y, linear_regression):\n",
    "    \n",
    "    data_X = StandardScaler().fit_transform(data_X)\n",
    "    predicted_values = linear_regression.predict(data_X)\n",
    "    \n",
    "    if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "        \n",
    "        predictions = predicted_values >= 0.5\n",
    "        predictions.astype(int)\n",
    "        metric = metric_score(data_Y, predictions)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for random forest. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#and the optimal value in that list will be picked using grid search\n",
    "def parameter_set_linear_regression(fit_intercept = [True], normalize = [False], copy_X = [True]):\n",
    "    \n",
    "    parameters_linear_regression = {}\n",
    "    parameters_linear_regression['fit_intercept'] = fit_intercept\n",
    "    parameters_linear_regression['normalize'] = normalize\n",
    "    \n",
    "    return parameters_linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trains the Logistic Regression  model. Performing a grid search to select the optimal parameter values\n",
    "def train_logistic_regression(train_X, train_Y, parameters_logistic_regression):\n",
    "\n",
    "    logistic_regression_model = linear_model.LogisticRegression()\n",
    "    train_X=StandardScaler().fit_transform(train_X)\n",
    "    model_gs = grid_search.GridSearchCV(logistic_regression_model, parameters_logistic_regression,\\\n",
    "                                        scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_logistic_regression(data_X, data_Y, logistic_regression):\n",
    "    \n",
    "    data_X = StandardScaler().fit_transform(data_X)\n",
    "    predicted_values = logistic_regression.predict_proba(data_X)[:, 1]\n",
    "    \n",
    "    if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "        \n",
    "        predictions = logistic_regression.predict(data_X)\n",
    "        metric = metric_score(data_Y, predictions)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for random forest. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#And the optimal value in that list will be picked using grid search\n",
    "def parameter_set_logistic_regression(penalty = ['l2'], dual = [False], tol = [0.0001], C = [1.0],\\\n",
    "                                      fit_intercept = [True], intercept_scaling = [1], class_weight = [None],\\\n",
    "                                      random_state = [None], solver = ['liblinear'], max_iter = [100],\\\n",
    "                                      multi_class = ['ovr'], verbose = [0], warm_start = [False]):\n",
    "    \n",
    "    parameters_logistic_regression = {}\n",
    "    parameters_logistic_regression['penalty'] = penalty\n",
    "    parameters_logistic_regression['dual'] = dual\n",
    "    parameters_logistic_regression['tol'] = tol\n",
    "    parameters_logistic_regression['C'] = C\n",
    "    parameters_logistic_regression['fit_intercept'] = fit_intercept\n",
    "    parameters_logistic_regression['intercept_scaling'] = intercept_scaling\n",
    "    parameters_logistic_regression['class_weight'] = class_weight\n",
    "    parameters_logistic_regression['solver'] = solver\n",
    "    parameters_logistic_regression['max_iter'] = max_iter\n",
    "    parameters_logistic_regression['multi_class'] = multi_class\n",
    "    parameters_logistic_regression['warm_start'] = warm_start\n",
    "    \n",
    "    return parameters_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The stacked ensmeble will be trained by using one or more of the base model algorithms\n",
    "#The function of the base model algorithm that will be used to train will be passed as the\n",
    "#model_function parameter and the parameters required to train the algorithm/model will be passed as the\n",
    "#model_parameters parameter\n",
    "def train_stack(data_X, data_Y, model_function, model_parameters):\n",
    "    \n",
    "    model = model_function(data_X, data_Y, model_parameters)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of stacked data, after the stacked model has been built by using a base model\n",
    "#algorithm, hence we need the predict funcction of that base model algorithm to get the predictions\n",
    "#The predict function of the base model is passed as the predict_function parameter and its respective model is \n",
    "#passed as the model parameter\n",
    "def predict_stack(data_X, data_Y, predict_function, model):\n",
    "    \n",
    "    metric,predicted_values = predict_function(data_X, data_Y, model)\n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The blending ensmeble will be trained by using one or more of the base model algorithms\n",
    "#The function of the base model algorithm that will be used to train will be passed as the\n",
    "#model_function parameter and the parameters required to train the algorithm/model will be passed as the\n",
    "#model_parameters parameter\n",
    "def train_blend(data_X, data_Y, model_function, model_parameters):\n",
    "    \n",
    "    model = model_function(blend_X, data_Y, model_parameters)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicts the output on a set of blended data, after the blending model has been built by using a base model\n",
    "#algorithm, hence we need the predict function of that base model algorithm to get the predictions\n",
    "#The predict function of the base model is passed as the predict_function parameter and its respective model is \n",
    "#passed as the model parameter\n",
    "def predict_blend(data_X, data_Y, predict_function, model):\n",
    "    \n",
    "    metric,predicted_values = predict_function(test_blend_X, data_Y, model)\n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perfroms weighted average of the predictions of the base models. The function that calculates the optimum \n",
    "# combination of weights is passsed as the get_weight_function parameter\n",
    "\n",
    "#The weight_list parameter contains the weights associated with the model, they are either default weights or a list\n",
    "#of weights. Using these weigths we either train the model or perform hyper parameter optimisation if there\n",
    "#is a list of weights that need to be checked to find the optimum weights\n",
    "def weighted_average(data_X, data_Y, hyper_parameter_optitmisation, weight_list):\n",
    "    \n",
    "    #Checking if hyper_parameter_optimisation is true\n",
    "    if(hyper_parameter_optitmisation == True):\n",
    "        \n",
    "        #The last element of the weight_list which indicates wether the user wants to perform hyper parameter \n",
    "        #optimisation is deleted\n",
    "        del weight_list[-1]\n",
    "        #Optimisation is performed by passing the weight_list we want to optimize\n",
    "        weight = get_optimized_weights(weight_list, data_X, data_Y)\n",
    "    \n",
    "    #Is none when performing weighted average on test data, we dont need to do anything else as we already have\n",
    "    #the weights for performing the weighted average\n",
    "    elif(hyper_parameter_optitmisation == None):\n",
    "        \n",
    "        weight = weight_list\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        #The last element of the weight_list which indicates wether the user wants to perform hyper parameter \n",
    "        #optimisation is deleted\n",
    "        del weight_list[-1]\n",
    "        #The weight_list is now used to calculate the weighted average\n",
    "        weight = weight_list\n",
    "        \n",
    "    weighted_avg_predictions=np.average(data_X, axis = 1, weights = weight)\n",
    "    metric = metric_score(data_Y, weighted_avg_predictions)\n",
    "    return [metric,weighted_avg_predictions,weight]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that finds the best possible combination of weights for performing the weighted predictions.\n",
    "def get_optimized_weights(weight_list, X, Y):\n",
    "    \n",
    "    space = assign_space_weighted_average(weight_list)\n",
    "    trials = Trials()\n",
    "    \n",
    "    best = fmin(fn = partial(objective_weighted_average, data_X = X, data_Y = Y),\n",
    "    space = space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 50,\n",
    "    trials = trials)\n",
    "    best_weights = list()\n",
    "    \n",
    "    #Arranging the weights in order of the respective models, and then returning the list of weights.\n",
    "    for key in sorted(best):\n",
    "        best_weights.append(best[key])\n",
    "    \n",
    "    return best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining the objective. Appropriate weights need to be calculated to minimize the loss.\n",
    "def objective_weighted_average(space, data_X, data_Y):\n",
    "    \n",
    "    weight_search_space = list()\n",
    "    \n",
    "    #Picking weights in the seacrh space to compute the best combination of weights\n",
    "    for weight in sorted(space):\n",
    "        weight_search_space.append(space[weight])\n",
    "    \n",
    "    weighted_avg_predictions = np.average(data_X, axis = 1, weights = weight_search_space)\n",
    "\n",
    "    metric = metric_score(data_Y, weighted_avg_predictions)\n",
    "    return{'loss':1-metric, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning the weights that need to be checked, for minimizing the objective (Loss)\n",
    "def assign_space_weighted_average(weight_list):\n",
    "    \n",
    "    space = {}\n",
    "    space_index = 0\n",
    "    \n",
    "    for weight in weight_list:\n",
    "        \n",
    "        #Assigning the search space, the search space is the range of weights that need to be searched for each \n",
    "        #base model, to find the weight of that base models predictions\n",
    "        space['w'+str(space_index )] = hp.choice('w'+str(space_index ), weight) \n",
    "        space_index = space_index + 1\n",
    "        \n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The user can either use the default weights or provide their own list of values.\n",
    "def assign_weights(weights = 'default',hyper_parameter_optimisation = False):\n",
    "    \n",
    "    weight_list = list()\n",
    "    \n",
    "    #The last element of the weight_list will indicate wether hyper parameter optimisation needs to be peroformed\n",
    "    if(hyper_parameter_optimisation == True):\n",
    "        \n",
    "        if(weights == 'default'):\n",
    "            \n",
    "            weight_list = [range(10)] * no_of_base_models\n",
    "            weight_list.append(True)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            weight_list = weights\n",
    "            weight_list.append(True)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if(weight == 'default'):\n",
    "            \n",
    "            weight_list = [1] * no_of_base_models\n",
    "            weight_list.append(False)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            weight_list = weights\n",
    "            weight_list.append(False)\n",
    "    \n",
    "    return weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for training and computing predictions for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Constructing a list (train_model_list) that contains a tuple for each base model, the tuple contains the name of \n",
    "#the function that trains the base model, and the paramters for training the base model. \n",
    "\n",
    "#Constructing a list (predict_model_list) that contains a tuple for each base model, the tuple contains the name of \n",
    "#the function that computes the predictions for the base model.\n",
    "\n",
    "#In the list computed for stacking and blending, the tuples have an additional element which is the train_stack \n",
    "#function or the train_blend function. This is done because different set of data (predictions of base models) \n",
    "#needs to be passed to the base model algorithms. These function enable performing the above procedure\n",
    "\n",
    "#These lists are constructed in such a way to enable the ease of use of the joblib library, i.e the parallel \n",
    "#module/function\n",
    "\n",
    "def construct_model_parameter_list(model_list, parameters_list, stack = False, blend = False):\n",
    "    \n",
    "    model_functions = {'gradient_boosting' : [train_gradient_boosting,predict_gradient_boosting],\n",
    "                       'decision_tree' : [train_decision_tree,predict_decision_tree],\n",
    "                       'random_forest' : [train_random_forest,predict_random_forest],\n",
    "                       'linear_regression' : [train_linear_regression,predict_linear_regression],\n",
    "                       'logistic_regression' : [train_logistic_regression,predict_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    train_model_list = list()\n",
    "    predict_model_list = list()\n",
    "    model_parameter_index = 0\n",
    "    \n",
    "    for model in model_list:\n",
    "        \n",
    "        if(stack == True):\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]\\\n",
    "                                         ,train_stack))\n",
    "            predict_model_list.append((model_functions[model][1],predict_stack))\n",
    "            \n",
    "        elif(blend == True):\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]\\\n",
    "                                         ,train_blend))\n",
    "            predict_model_list.append((model_functions[model][1],predict_blend))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]))\n",
    "            predict_model_list.append(model_functions[model][1])\n",
    "            \n",
    "        model_parameter_index = model_parameter_index + 1\n",
    "        \n",
    "    return [train_model_list,predict_model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes a list where each element is a tuple that contains the predict function of the base model\n",
    "#along with the corresponding base model object. This is done so that the base model object can be passed to the\n",
    "#predict function as a prameter to compute the predictions when using joblib's parallel module/function. \n",
    "def construct_model_predict_function_list(model_list, models,predict_model_list):\n",
    "    \n",
    "    model_index = 0\n",
    "    model_function_list = list()\n",
    "    for model in model_list:\n",
    "        \n",
    "        model_function_list.append((predict_model_list[model_index],models[model_index]))\n",
    "        model_index = model_index + 1\n",
    "    return model_function_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function calls the respective training and predic functions of the base models.\n",
    "def train_base_models(model_list, parameters_list, save_models = False):\n",
    "    \n",
    "    print('\\nTRAINING BASE MODELS\\n')\n",
    "    \n",
    "    #Cross Validation using Stratified K Fold\n",
    "    train, cross_val = train_test_split(Data, test_size = 0.5, stratify = Data[target_label],random_state = 0)\n",
    "    \n",
    "    #Training the base models, and calculating AUC on the cross validation data.\n",
    "    #Selecting the data (Traing Data & Cross Validation Data)\n",
    "    train_Y = train[target_label]\n",
    "    train_X = train.drop([target_label],axis=1)\n",
    " \n",
    "    cross_val_Y = cross_val[target_label]\n",
    "    cross_val_X = cross_val.drop([target_label],axis=1)\n",
    "    \n",
    "    #The list of base models the user wants to train.\n",
    "    global base_model_list\n",
    "    base_model_list = model_list\n",
    "\n",
    "    \n",
    "    #No of base models that user wants to train\n",
    "    global no_of_base_models\n",
    "    no_of_base_models = len(base_model_list)\n",
    "    \n",
    "    \n",
    "    #We get the list of base model training functions and predict functions. The elements of the two lists are  \n",
    "    #tuples that have (base model training function,model parameters), (base model predict functions) respectively\n",
    "    [train_base_model_list,predict_base_model_list] = construct_model_parameter_list(base_model_list,\\\n",
    "                                                                                     parameters_list)\n",
    "    \n",
    "\n",
    "    #Training the base models parallely, the resulting models are stored which will be used for cross validation.\n",
    "    models = (Parallel(n_jobs = -1)(delayed(function)(train_X, train_Y, model_parameter)\\\n",
    "                                                   for function, model_parameter in train_base_model_list))\n",
    "    \n",
    "    if(save_models == True):\n",
    "        \n",
    "        save_base_models(models)\n",
    "    \n",
    "    \n",
    "    #A list with elements as tuples containing (base model predict function, and its respective model object) is \n",
    "    #returned. This list is used in the next step in the predict_base_models function, the list will be used in\n",
    "    #joblibs parallel module/function to compute the predictions and metric scores of the base models\n",
    "    #Appended in the following manner so it can be used in joblib's parallel module/function\n",
    "    global base_model_predict_function_list\n",
    "    base_model_predict_function_list = construct_model_predict_function_list(base_model_list, models,\\\n",
    "                                                                        predict_base_model_list)\n",
    "    predict_base_models(cross_val_X, cross_val_Y,mode = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions of base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_base_models(data_X, data_Y,mode):\n",
    "    \n",
    "    print('\\nTESTING/CROSS VALIDATION BASE MODELS\\n')\n",
    "    \n",
    "    predict_list = list()\n",
    "    \n",
    "    predict_gradient_boosting = list()\n",
    "    predict_multi_layer_perceptron = list()\n",
    "    predict_decision_tree = list()\n",
    "    predict_random_forest = list()\n",
    "    predict_linear_regression = list()\n",
    "    predict_logistic_regression = list()\n",
    "    \n",
    "    metric_linear_regression = list()\n",
    "    metric_logistic_regression = list()\n",
    "    metric_decision_tree = list()\n",
    "    metric_random_forest = list()\n",
    "    metric_multi_layer_perceptron = list()\n",
    "    metric_gradient_boosting = list()\n",
    "    \n",
    "    auc_predict_index = 0\n",
    "    \n",
    "    #Initializing a list which will contain the predictions of the base models and the variables that will\n",
    "    #calculate the metric score\n",
    "    model_predict_metric = {'gradient_boosting' : [predict_gradient_boosting, metric_gradient_boosting],\n",
    "                       'multi_layer_perceptron' : [predict_multi_layer_perceptron, metric_multi_layer_perceptron],\n",
    "                       'decision_tree' : [predict_decision_tree, metric_decision_tree],\n",
    "                       'random_forest' : [predict_random_forest, metric_random_forest],\n",
    "                       'linear_regression' : [predict_linear_regression, metric_linear_regression],\n",
    "                       'logistic_regression' : [predict_logistic_regression, metric_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    #Computing the AUC and Predictions of all the base models on the cross validation data parallely.\n",
    "    auc_predict_cross_val = (Parallel(n_jobs = -1)(delayed(function)(data_X, data_Y, model)\n",
    "                                               for function, model in base_model_predict_function_list))\n",
    "    \n",
    "    #Building the list which will contain all the predictions of the base models and will also display the metric\n",
    "    #scores of the base models\n",
    "    for model in base_model_list:\n",
    "        \n",
    "        #Assigning the predictions and metrics computed for the respective base model\n",
    "        model_predict_metric[model] = auc_predict_cross_val[auc_predict_index][1],\\\n",
    "        auc_predict_cross_val[auc_predict_index][0]\n",
    "        auc_predict_index = auc_predict_index + 1\n",
    "        \n",
    "        if(model == 'multi_layer_perceptron'):\n",
    "            \n",
    "            #This is done only for multi layer perceptron because the predictions returned by the multi layer \n",
    "            #perceptron model is a list of list, the below pice of code converts this nested list into a single\n",
    "            #list\n",
    "            predict_list.append(np.asarray(sum(model_predict_metric[model][0].tolist(), [])))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #The below list will contain all the predictions of the base models.\n",
    "            predict_list.append(model_predict_metric[model][0])\n",
    "        \n",
    "        #Printing the name of the base model and its corresponding metric score\n",
    "        print_metric(model,model_predict_metric[model][1])\n",
    "    \n",
    "    if(mode == 'train'):\n",
    "        \n",
    "        #Function to construct dataframes for training the second level/ensmeble models using the predictions of the\n",
    "        #base models on the train dataset\n",
    "        second_level_train_data(predict_list, data_X, data_Y)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #Function to construct dataframes for testing the second level/ensmeble models using the predictions of the\n",
    "        #base models on the test dataset\n",
    "        second_level_test_data(predict_list, data_X, data_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The trained base model objects can be saved and used later for any other purpose. The models asre save using \n",
    "#joblib's dump. The models are named base_model1, base_model2..so on depending on the order entered by the user\n",
    "#while training these models in the train_base_model function\n",
    "def save_base_models(models):\n",
    "    \n",
    "    model_index = 0\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        joblib.dump(model, 'base_model'+str(model_index)+'.pkl')\n",
    "        model_index = model_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function will return the trained base model objects once they have been saved in the function above. All the \n",
    "#trained models are returned in a list called models\n",
    "def get_base_models():\n",
    "    \n",
    "    models = list()\n",
    "    \n",
    "    for model_index in range(no_of_base_models):\n",
    "        models.append(joblib.load('base_model'+str(model_index)+'.pkl'))\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ensemble/second level models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training the second level models parallely\n",
    "def train_ensemble_models(stack_model_list = [], stack_parameters_list = [], blend_model_list = [],\\\n",
    "                              blend_parameters_list = [], perform_weighted_average = None, weights_list = None,\n",
    "                          save_models = False):\n",
    "    \n",
    "    print('\\nTRAINING ENSEMBLE MODELS\\n')\n",
    "    \n",
    "    global no_of_ensemble_models\n",
    "    \n",
    "    #This list will contain the names of the models/algorithms that have been used as second level models\n",
    "    #This list will be used later in the testing phase for identifying which model belongs to which ensemble\n",
    "    #(stacking or blending), hence the use of dictionaries as elements of the list\n",
    "    #Analogous to the base_model_list\n",
    "    global ensmeble_model_list\n",
    "    ensmeble_model_list = list()\n",
    "    \n",
    "    train_stack_model_list = list() \n",
    "    predict_stack_model_list = list()\n",
    "    train_blend_model_list = list()\n",
    "    predict_blend_model_list = list()\n",
    "    \n",
    "    #The list will be used to train the ensemble models, while using joblib's parallel\n",
    "    train_second_level_models = list() \n",
    "    \n",
    "    #Stacking will not be done if user does not enter the list of models he wants to use for stacking\n",
    "    if(stack_model_list != []):\n",
    "        \n",
    "        #Appending a dictionary that contians key-Stacking and its values/elements are the names of the \n",
    "        #models/algorithms that are used for performing the stacking procedure, this is done so that it will be easy\n",
    "        #to identify the models belonging to the stacking ensemble\n",
    "        ensmeble_model_list.append({'Stacking' : stack_model_list})\n",
    "        \n",
    "        #We get the list of stacked model training functions and predict functions. The elements of the two   \n",
    "        #lists are tuples that have(base model training function,model parameters,train_stack function),\n",
    "        #(base model predict functions,predict_stack function) respectively\n",
    "        [train_stack_model_list,predict_stack_model_list] = construct_model_parameter_list(stack_model_list,\\\n",
    "                                                                                           stack_parameters_list,\n",
    "                                                                                           stack=True)\n",
    "        \n",
    "    #Blending will not be done if user does not enter the list of models he wants to use for blending\n",
    "    if(blend_model_list != []):\n",
    "        \n",
    "        #Appending a dictionary that contians key-Blending and its values/elements are the names of the \n",
    "        #models/algorithms that are used for performing the blending procedure, this is done so that it will be easy\n",
    "        #to identify the models belonging to the blending ensemble\n",
    "        ensmeble_model_list.append({'Blending' : blend_model_list})\n",
    "\n",
    "        #We get the list of blending model training functions and predict functions. The elements of the two   \n",
    "        #lists are tuples that have(base model training function,model parameters,train_blend function),\n",
    "        #(base model predict functions,predict_blend function) respectively\n",
    "        [train_blend_model_list,predict_blend_model_list] = construct_model_parameter_list(blend_model_list,\\\n",
    "                                                                                           blend_parameters_list,\\\n",
    "                                                                                           blend=True)\n",
    "        \n",
    "    #The new list contains either the stacked models or blending models or both or remain empty depending on what \n",
    "    #the user has decided to use\n",
    "    train_second_level_models = train_stack_model_list + train_blend_model_list\n",
    "    \n",
    "    #If the user wants to perform a weighted average, a tuple containing (hyper parmeter optimisation = True/False,\n",
    "    #the lsit of weights either deafult or entered by the user, and the function that performs the weighted average)\n",
    "    #will be created. This tuple will be appended to the list above\n",
    "    #weights_list[-1] is an element of the list that indicates wwether hyper parameter optimisation needs to be\n",
    "    #perofrmed\n",
    "    if(perform_weighted_average == True):\n",
    "        \n",
    "        train_weighted_average_list = (weights_list[-1], weights_list, weighted_average)\n",
    "        train_second_level_models.append(train_weighted_average_list)\n",
    "\n",
    "        \n",
    "    no_of_ensemble_models = len(train_second_level_models)\n",
    "\n",
    "    #If weighted average is performed, the last element of models will contain the metric score and weighted average\n",
    "    #predictions, and not a model object. So we use the last element in different ways compared to the other model\n",
    "    #objects\n",
    "    \n",
    "    #Training the ensmeble models parallely \n",
    "    models = Parallel(n_jobs = -1)(delayed(function)(stack_X, stack_Y, model, model_parameter)\\\n",
    "                                        for model, model_parameter, function in train_second_level_models)\n",
    "    \n",
    "    \n",
    "    #A list with elements as tuples containing((base model predict function,predict_stack or predict_blend functions)\n",
    "    #,and its respective base model object) is returned. This list is used in the next step in the   \n",
    "    #predict_ensemble_models function, the list will be used in\n",
    "    #joblibs parallel module/function to compute the predictions and metric score of the ensemble models\n",
    "    #Appended in the following manner so it can be used in joblib's parallel module/function\n",
    "    #Analogous to base_model_predict_function_list\n",
    "    global ensmeble_model_predict_function_list\n",
    "    ensmeble_model_predict_function_list = construct_model_predict_function_list(stack_model_list + blend_model_list,\\\n",
    "                                                                                 models, predict_stack_model_list \n",
    "                                                                                 + predict_blend_model_list)\n",
    "    \n",
    "    #If weighted average is needed to be perofrmed we need to append((None(which indicates its testing phase),the\n",
    "    #weighted average function),and the weights). Appended in the following manner so it can be used in joblib's\n",
    "    #parallel module/function\n",
    "    if(perform_weighted_average == True):\n",
    "        \n",
    "        weight = models[-1][-1]\n",
    "        print('Weighted Average')\n",
    "        print('Weight',weight)\n",
    "        print('Metric Score',models[-1][0])\n",
    "        ensmeble_model_list.append({'Weighted Average' : [str(weight)]})\n",
    "        ensmeble_model_predict_function_list.append(((None,weighted_average),weight))\n",
    "        \n",
    "    if(save_models == True and perform_weighted_average == True):\n",
    "        \n",
    "        del models[-1]\n",
    "        no_of_ensemble_models = no_of_ensemble_models - 1\n",
    "        save_ensemble_models(models)\n",
    "        \n",
    "    elif(save_models == True and perform_weighted_average == True):\n",
    "        \n",
    "        save_ensemble_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_ensemble_models(data_X, data_Y):\n",
    "    \n",
    "    print('\\nTESTING ENSEMBLE MODELS\\n')\n",
    "\n",
    "    metric_linear_regression = list()\n",
    "    metric_logistic_regression = list()\n",
    "    metric_decision_tree = list()\n",
    "    metric_random_forest = list()\n",
    "    metric_multi_layer_perceptron = list()\n",
    "    metric_gradient_boosting = list()\n",
    "    metric_weighted_average = list()\n",
    "    metric_stacking = list()\n",
    "    metric_blending = list()\n",
    "    \n",
    "    auc_predict_index = 0\n",
    "    \n",
    "    #Initializing a list which will contain the predictions of the base models and the variables that will\n",
    "    #calculate the metric score\n",
    "    model_metric = {'gradient_boosting' : [metric_gradient_boosting],\n",
    "                       'multi_layer_perceptron' : [metric_multi_layer_perceptron],\n",
    "                       'decision_tree' : [metric_decision_tree],\n",
    "                       'random_forest' : [metric_random_forest],\n",
    "                       'linear_regression' : [metric_linear_regression],\n",
    "                       'logistic_regression' : [metric_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    #Computing the AUC and Predictions of all the ensmeble models on the test data parallely.\n",
    "    auc_predict_cross_val = (Parallel(n_jobs = -1)(delayed(function[1])(data_X, data_Y, function[0],model)\n",
    "                                               for function, model in ensmeble_model_predict_function_list))\n",
    "    \n",
    "    #ensemble_model_list is a list defined in the train_ensemble_models function, each element of the lsit is a\n",
    "    #dictionary, that contains the name of the ensembling technique (key) and the models assocaited with it(values)\n",
    "    \n",
    "    #So the first for loop gives the dictionary\n",
    "    for ensemble_models in ensmeble_model_list:\n",
    "    \n",
    "        #This for gives the key value pair, key being the name of the ensembling technique, value being a list\n",
    "        #of the models used for that ensemble\n",
    "        for ensemble,models in ensemble_models.items():\n",
    "            \n",
    "            #This for loop gives the iterates through the models present in the models list adn asssigns \n",
    "            #the metric score and prints it\n",
    "            for model in models:\n",
    "                \n",
    "                #Assigning the predictions and metrics computed for the respective ensmeble model\n",
    "                model_metric[model] = auc_predict_cross_val[auc_predict_index][0]\n",
    "                auc_predict_index = auc_predict_index + 1\n",
    "        \n",
    "                #Printing the name of the ensmeble technique and its model and its corresponding metric score\n",
    "                print_metric(ensemble + \" \" + model,model_metric[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The trained ensmeble model objects can be saved and used later for any other purpose. The models asre save using \n",
    "#joblib's dump. The models are named ensmeble_model1, emnsmeble_model2..so on depending on the order entered by \n",
    "#the user while training these models in the train_base_model function\n",
    "def save_ensemble_models(models):\n",
    "    \n",
    "    model_index = 0\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        joblib.dump(model, 'ensemble_model'+str(model_index)+'.pkl')\n",
    "        model_index = model_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function will return the trained base model objects once they have been saved in the function above. All the \n",
    "#trained models are returned in a list called models\n",
    "def get_ensemble_models():\n",
    "    \n",
    "    models = list()\n",
    "    \n",
    "    for model_index in range(no_of_ensemble_models):\n",
    "        models.append(joblib.load('ensemble_model'+str(model_index)+'.pkl'))\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_models(test_data):\n",
    "    \n",
    "    print('\\nTESTING PHASE\\n')\n",
    "    \n",
    "    #Training the base models, and calculating AUC on the test data.\n",
    "    #Selecting the data (Test Data)\n",
    "    test_Y = test_data[target_label]\n",
    "    test_X = test_data.drop([target_label],axis=1)\n",
    "    \n",
    "    predict_base_models(test_X,test_Y,mode='test')\n",
    "    predict_ensemble_models(test_stack_X,test_stack_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_metric(model,metric_score):\n",
    " \n",
    "    #Printing the metric score for the corresponding model.\n",
    "    print (model,'\\n',metric_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "gradient_boosting \n",
      " 0.944007203548\n",
      "decision_tree \n",
      " 0.911467984724\n",
      "random_forest \n",
      " 0.915514661257\n",
      "linear_regression \n",
      " 0.930442017332\n",
      "logistic_regression \n",
      " 0.933491399528\n",
      "logistic_regression \n",
      " 0.933506586629\n",
      "gradient_boosting \n",
      " 0.920428109702\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "Weighted Average\n",
      "Weight [7, 7, 7, 3, 1, 3, 6]\n",
      "Metric Score 0.944888729332\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "gradient_boosting \n",
      " 0.947977924797\n",
      "decision_tree \n",
      " 0.914875636167\n",
      "random_forest \n",
      " 0.918919786573\n",
      "linear_regression \n",
      " 0.931387192006\n",
      "logistic_regression \n",
      " 0.932993891221\n",
      "logistic_regression \n",
      " 0.933046697695\n",
      "gradient_boosting \n",
      " 0.915598416592\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Stacking linear_regression \n",
      " 0.949560251794\n",
      "Stacking gradient_boosting \n",
      " 0.945653064086\n",
      "Blending gradient_boosting \n",
      " 0.94715899859\n",
      "Blending logistic_regression \n",
      " 0.946262598865\n",
      "Weighted Average [7, 7, 7, 3, 1, 3, 6] \n",
      " 0.947654501523\n",
      "CPU times: user 2.53 s, sys: 228 ms, total: 2.76 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_test = data_import(Data,label_output='y')\n",
    "metric_set('roc_auc_score')\n",
    "param_gb_1 = parameter_set_gradient_boosting(eval_metric = ['auc'], objective = ['binary:logistic'])\n",
    "param_dt = parameter_set_decision_tree(max_depth = [6])\n",
    "param_rf = parameter_set_random_forest()\n",
    "param_lr = parameter_set_linear_regression()\n",
    "param_l2 = parameter_set_logistic_regression()\n",
    "param_l1 = parameter_set_logistic_regression(penalty = ['l1'])\n",
    "param_gb_2 = parameter_set_gradient_boosting(eval_metric = ['auc'], objective = ['binary:logistic'],\n",
    "                                                booster=['gblinear'], eta = [0.1,0.3,0.5,0.7],\n",
    "                                               hyper_parameter_optimisation = True)\n",
    "\n",
    "train_base_models(['gradient_boosting','decision_tree',\\\n",
    "                                     'random_forest','linear_regression','logistic_regression',\\\n",
    "                                     'logistic_regression','gradient_boosting'],[param_gb_1, param_dt, param_rf\n",
    "                                                                                 ,param_lr, param_l2, param_l1,\n",
    "                                                                                 param_gb_2])\n",
    "\n",
    "weights = assign_weights(weights = 'default', hyper_parameter_optimisation = True)\n",
    "\n",
    "\n",
    "train_ensemble_models(['linear_regression', 'gradient_boosting'], [param_lr, param_gb_1],\n",
    "                      ['gradient_boosting','logistic_regression'],[param_gb_1,param_l2], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "test_models(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
